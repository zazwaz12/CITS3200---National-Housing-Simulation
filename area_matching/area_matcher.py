# -*- coding: utf-8 -*-
"""area_matcher.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VdSIUrnbYDXj90L8VGsv_RcwOM_ZkVRD
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install geopandas

import geopandas as gpd
import pandas as pd
from shapely.geometry import Point
import fiona

# Set the SHAPE_RESTORE_SHX option
fiona.drvsupport.supported_drivers['ESRI Shapefile'] = 'rw'
fiona.drvsupport.supported_drivers['SHAPE_RESTORE_SHX'] = 'YES'

# Read the shapefile
shapefile_path = "/content/SA1_2021_AUST_GDA2020.shp"
total_rows = len(gpd.read_file(shapefile_path))
print(f"Total number of rows in the shapefile: {total_rows}")

# Read the CSV file
csv_path = "/content/houses-sample.csv"
houses_df = pd.read_csv(csv_path)
print(houses_df.head())  # Print the first few rows of the CSV file

import geopandas as gpd
import pandas as pd
from pyproj import CRS
import multiprocessing as mp
import numpy as np

# Load the points from the CSV file
csv_path = "/content/houses-sample.csv"
pnts = pd.read_csv(csv_path)

if 'LONGITUDE' in pnts.columns and 'LATITUDE' in pnts.columns:
    pnts = pnts.rename(columns={'LONGITUDE': 'x', 'LATITUDE': 'y'})

# Convert points to GeoDataFrame
pnts_gdf = gpd.GeoDataFrame(
    pnts,
    geometry=gpd.points_from_xy(pnts.x, pnts.y),
    crs="EPSG:7844"
)

# Project to a suitable projected CRS (GDA2020 / MGA zone 55)
projected_crs = CRS.from_epsg(7844)
pnts_gdf = pnts_gdf.to_crs(projected_crs)

# Read the entire shapefile
map_data = gpd.read_file("/content/SA1_2021_AUST_GDA2020.shp")
map_data = map_data.to_crs(projected_crs)

# Create spatial index for the polygons
spatial_index = map_data.sindex

def process_chunk(chunk):
    # Perform spatial join for this chunk
    pnts_with_area = gpd.sjoin(chunk, map_data, how="left", predicate='within')

    # Identify points without an assigned area
    missing_points = pnts_with_area[pnts_with_area['SA2_NAME21'].isnull()]

    if not missing_points.empty:
        # Perform nearest join for missing points
        nearest_join = gpd.sjoin_nearest(missing_points[['geometry']], map_data, how="left")

        # Update the main result with nearest join results
        pnts_with_area.loc[missing_points.index, 'SA2_NAME21'] = nearest_join['SA2_NAME21']
        pnts_with_area.loc[missing_points.index, 'SA2_CODE21'] = nearest_join['SA2_CODE21']

    # Select and rename relevant columns
    result = pnts_with_area[['x', 'y', 'SA2_NAME21', 'SA2_CODE21']]
    result = result.rename(columns={'SA2_NAME21': 'area', 'SA2_CODE21': 'area_code'})
    return result

# Split points into chunks for parallel processing
num_cores = mp.cpu_count()
chunks = np.array_split(pnts_gdf, num_cores)

# Parallel processing
with mp.Pool(num_cores) as pool:
    all_results = pool.map(process_chunk, chunks)

# Combine all results
final_result = pd.concat(all_results, ignore_index=True)

# Check if there are still any missing areas
if final_result['area'].isnull().any() or final_result['area_code'].isnull().any():
    print("Warning: Some points were not assigned to an SA2 area even after nearest join. Please check your data.")

print(final_result)

# Merge the final_result with the original points DataFrame to add area and area_code
houses_with_areas = pd.merge(pnts, final_result, on=['x', 'y'], how='left')

# Save the result to a CSV file
output_csv_path = "/content/houses_with_areas.csv"
houses_with_areas.to_csv(output_csv_path, index=False)

print(f"CSV file saved to: {output_csv_path}")

# Display the first few rows of the resulting DataFrame
print(houses_with_areas.head())

# Count the number of missing values in the 'area' column
missing_area_count = final_result['area'].isnull().sum()

print(f"Number of missing values in the 'area' column: {missing_area_count}")

# Merge the final_result with the original points DataFrame to add area and area_code
houses_with_areas = pd.merge(pnts, final_result, on=['x', 'y'], how='left')

# Display the resulting DataFrame with the new columns
houses_with_areas

output_csv_path = "/content/houses_with_areas2.csv"
houses_with_areas.to_csv(output_csv_path, index=False)

print(f"CSV file saved to: {output_csv_path}")

# Display the first few rows of the resulting DataFrame
houses_with_areas.head()

print(pnts_gdf.crs)
print(map_chunk.crs)